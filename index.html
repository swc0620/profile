<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Woochul Shin</title>
  <meta name="author" content="Woochul Shin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Woochul Shin
                  </p>
                  <p>I'm a master's student majoring in CS at
                    <a href="https://www.cc.gatech.edu/">Georgia Tech</a>,
                    where I am advised by Prof. <a href="https://faculty.cc.gatech.edu/~danfei/">Danfei Xu</a>.
                  </p>
                  <p>
                    I earned my undergraduate degree at <a href="https://en.snu.ac.kr/">Seoul National University</a> where I double majored in Artificial Intelligence and Economics.
                  </p>
                  <p>
                    Please feel free to check out my CV and drop me an email if you want to chat!
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:loopdewoo@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=dToGVDIAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://drive.google.com/file/d/1YLbdbqdEelH2K_OX1XqsX7pScckiqNka/view?usp=sharing">CV</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/woochulshin">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/swc0620/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/me.jpg" class="hoverZoomLink" />
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in robotics, particularly in robot learning and manipulation, computer vision, and machine learning. My research interests include enabling robots to perform dexterous manipulation in dynamic and complex environments, learning to perceive and interact with the world effectively, and optimizing task-dependent robot design for enhanced performance.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                    <source src="images/immimic.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                </div>
                <!-- <script type="text/javascript">
                  function r2r_start() {
                    document.getElementById('r2r_image').style.opacity = "1";
                  }
                  function r2r_stop() {
                    document.getElementById('r2r_image').style.opacity = "0";
                  }
                  r2r_stop()
                </script> -->
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle"><a href="https://sites.google.com/view/immimic">ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation</a></span>
                <br>
                <i>Yangcen Liu*</i>,
                <strong>Woo Chul Shin*</strong>,
                <i>Yunhai Han</i>,
                <i>Zhenyang Chen</i>,
                <i>Harish Ravichandar</i>,
                <i>Danfei Xu</i>,
                <br>
                <em>Under Review</em>, 2025
                <br>
                <a href="https://sites.google.com/view/immimic">project page</a>
                <!-- /
                <a href="https://arxiv.org/abs/2412.15211">arXiv</a> -->
                <p></p>
                <p>
                  ImMimic is an embodiment-agnostic co-training framework that bridges the domain gap between large-scale human videos and limited robot demonstrations. It uses Dynamic Time Warping to map human hand poses to robot joints and applies MixUp interpolation to generate intermediate domains for smoother domain adaptation. Evaluations across two parallel-jaw grippers (Robotiq, Fin Ray) and two dexterous hands (Ability, Allegro) demonstrate that ImMimic significantly improves task success and execution smoothness.
                </p>
              </td>
            </tr>


            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                    <source src="images/sail.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                </div>
                <!-- <script type="text/javascript">
                  function r2r_start() {
                    document.getElementById('r2r_image').style.opacity = "1";
                  }
                  function r2r_stop() {
                    document.getElementById('r2r_image').style.opacity = "0";
                  }
                  r2r_stop()
                </script> -->
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle"><a href="https://sail-robot.github.io/">SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies</a></span>
                <br>
                <i>Nadun Ranawaka Arachchige*</i>,
                <i>Zhenyang Chen*</i>,
                <i>Wonsuhk Jung</i>,
                <strong>Woo Chul Shin</strong>, 
                <i>Rohan Bansal</i>,
                <i>Pierre Barroso</i>,
                <i>Yu Hang He</i>,
                <i>Yingyan Celine Lin</i>,
                <i>Benjamin Joffe</i>,
                <i>Shreyas Kousik<sup>&dagger;</sup></i>,
                <i>Danfei Xu<sup>&dagger;</sup></i>
                <br>
                <em>Under Review</em>, 2025
                <br>
                <a href="https://sail-robot.github.io/">project page</a>
                <!-- /
                <a href="https://arxiv.org/abs/2412.15211">arXiv</a> -->
                <p></p>
                <p>
                  We propose SAIL (Speed-Adaptive Imitation Learning), a framework for enabling faster-than- demonstration execution of policies by addressing key technical challenges in robot dynamics and state-action distribution shifts. SAIL achieves up to a 4× speedup over demonstration speed in simulation and up to 3.2× speedup on physical robot.
                </p>
              </td>
            </tr>
            

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <!-- <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
                    <source src="images/r2r.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div> -->
                  <img src='images/mimiclabs.jpg' width=100%>
                </div>
                <!-- <script type="text/javascript">
                  function r2r_start() {
                    document.getElementById('r2r_image').style.opacity = "1";
                  }
                  function r2r_stop() {
                    document.getElementById('r2r_image').style.opacity = "0";
                  }
                  r2r_stop()
                </script> -->
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle"><a href="https://robo-mimiclabs.github.io/pages/study.html">What Matters in Learning from Large-Scale Datasets for Robot Manipulation</a></span>
                <br>
                <i>Vaibhav Saxena*</i>,
                <i>Matthew Bronars*</i>,
                <i>Nadun Ranawaka*</i>,
                <i>Kuancheng Wang</i>,
                <strong>Woo Chul Shin</strong>, 
                <i>Soroush Nasiriany</i>,
                <i>Ajay Mandlekar<sup>&dagger;</sup></i>,
                <i>Danfei Xu<sup>&dagger;</sup></i>
                <br>
                <em>ICLR</em>, 2025
                <br>
                <a href="https://robo-mimiclabs.github.io/pages/study.html">project page</a>
                <!-- /
                <a href="https://arxiv.org/abs/2412.15211">arXiv</a> -->
                <p></p>
                <p>
                  We develop MimicLabs, a data generation framework to procedurally emulate key sources of diversity in robot datasets. Using this framework, we generate large-scale datasets with controlled variations to analyze how collection diversity and retrieval strategies impact downstream policy learning.
                </p>
              </td>
            </tr>
        </td>
      </tr>
  </table>
</body>

</html>